{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Session 11: Advanced Retrieval with LangChain\n",
        "\n",
        "## Learning Objectives:\n",
        "\n",
        "- Understand and implement multiple retrieval strategies for RAG\n",
        "- Compare naive, BM25, multi-query, parent-document, contextual compression, ensemble, and semantic chunking approaches\n",
        "- Build RAG chains over a health and wellness knowledge base using LangChain and QDrant\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "---\n",
        "\n",
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key.\n",
        "\n",
        "> NOTE: Create a `.env` file in this directory with `OPENAI_API_KEY` and `COHERE_API_KEY` to avoid being prompted each time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "if not os.environ.get(\"COHERE_API_KEY\"):\n",
        "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Health and Wellness Guide - a comprehensive resource covering exercise, nutrition, sleep, stress management, habits, and common health concerns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll load the wellness guide as a single document, then split it into smaller chunks using a `RecursiveCharacterTextSplitter` for our vector store. We also keep the raw (unsplit) document for use with the Parent Document Retriever and Semantic Chunker later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = TextLoader(\"data/HealthWellnessGuide.txt\")\n",
        "raw_docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "wellness_docs = text_splitter.split_documents(raw_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's verify our data was loaded and split correctly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw documents: 1\n",
            "Split chunks: 45\n",
            "\n",
            "Example chunk:\n",
            "page_content='The Personal Wellness Guide\n",
            "A Comprehensive Resource for Health and Well-being\n",
            "\n",
            "PART 1: EXERCISE AND MOVEMENT\n",
            "\n",
            "Chapter 1: Understanding Exercise Basics\n",
            "\n",
            "Exercise is one of the most important things you can do for your health. Regular physical activity can improve your brain health, help manage weight, reduce the risk of disease, strengthen bones and muscles, and improve your ability to do everyday activities.' metadata={'source': 'data/HealthWellnessGuide.txt'}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Raw documents: {len(raw_docs)}\")\n",
        "print(f\"Split chunks: {len(wellness_docs)}\")\n",
        "print(f\"\\nExample chunk:\\n{wellness_docs[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"wellness_guide\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = QdrantVectorStore.from_documents(\n",
        "    wellness_docs,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"wellness_guide\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the information provided, here are some exercises that can help alleviate lower back pain:\\n\\n1. Cat-Cow Stretch:\\n- Start on your hands and knees.\\n- Alternate between arching your back up (cat position) and letting it sag down (cow position).\\n- Repeat for 10-15 repetitions.\\n\\n2. Bird Dog:\\n- Begin on your hands and knees.\\n- Extend opposite arm and leg simultaneously while keeping your core engaged.\\n- Hold each extension for about 5 seconds.\\n- Switch sides and repeat for 10 repetitions per side.\\n\\n3. Pelvic Tilts:\\n- Lie on your back with knees bent.\\n- Flatten your back against the floor by tightening your abdominal muscles and tilting your pelvis upward.\\n- Hold for 10 seconds.\\n- Repeat 8-12 times.\\n\\nThese exercises are gentle and aimed at stretching and strengthening the lower back muscles, which can help reduce pain and improve mobility. Remember to perform these exercises slowly and consult with a healthcare professional if you have any concerns or specific medical conditions.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep has a significant impact on overall health. Adequate and quality sleepâ€”typically 7-9 hours per nightâ€”supports physical health by allowing the body to repair tissues, regulate hormones, and strengthen the immune system. It also enhances mental well-being, cognitive functions such as memory and learning, and mood stability. Poor sleep or sleep disorders like insomnia can negatively affect these processes, leading to increased health risks, weakened immunity, and mental health issues. Maintaining good sleep hygiene and creating an optimal sleep environment are essential strategies for promoting overall health.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress and headaches include:\\n\\n- Drinking water and staying hydrated\\n- Applying cold or warm compresses to the head or neck\\n- Resting in a dark, quiet room\\n- Gentle massage of the temples and neck\\n- Using peppermint or lavender essential oils\\n- Maintaining a regular sleep schedule\\n- Practicing deep breathing, progressive muscle relaxation, or grounding techniques\\n- Taking short walks in nature\\n- Listening to calming music\\n\\nThese approaches can help alleviate stress and headache symptoms naturally.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(wellness_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Exercises that can help with lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on your hands and knees. Alternate between arching your back up (cat) and letting it sag down (cow). Perform 10-15 repetitions.\\n- **Bird Dog:** From your hands and knees, extend opposite arm and leg while keeping your core engaged. Hold each extension for 5 seconds, then switch sides. Do 10 repetitions per side.\\n- **Pelvic Tilts:** Lie on your back with knees bent. Flatten your lower back against the floor by tightening your abdominal muscles and tilting your pelvis slightly upward. Hold for 10 seconds and repeat 8-12 times.\\n\\nThese gentle stretching and strengthening exercises can help alleviate lower back discomfort and prevent future episodes.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep plays a crucial role in overall health. Good sleep hygiene and a consistent sleep schedule help ensure quality sleep, which is essential for physical and mental well-being. Adequate sleep supports the immune system, improves mood, boosts energy levels, enhances cognitive function, and promotes better digestive health. Creating an optimal sleep environmentâ€”such as maintaining a cool, dark, quiet bedroom and avoiding stimulating activities before bedâ€”can significantly improve sleep quality. Poor or insufficient sleep can lead to health issues like impaired immunity, mental health challenges, and increased risk of chronic conditions.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress include practicing relaxation techniques such as deep breathing and meditation. For headaches, staying well-hydrated, managing stress through relaxation, ensuring adequate sleep, and avoiding known triggers like certain foods or eye strain can help reduce their frequency and intensity. Herbal teas like chamomile or valerian root may also promote relaxation and help alleviate headaches related to stress.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### â“ Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer.\n",
        "\n",
        "##### Answer:\n",
        "\n",
        "Better where we want to do specific and exact keyword matching and less bothered by semantic meaning. \n",
        "For example if searching for a product via its name or a product code (like ASIN on Amazon.com) then BM25 is likely to be better, since we are uninterested in semantically similar product codes. \n",
        "Same goes when looking up a programming error code like a 400 error etc. Really the ony interest at this particular time is in that exact error not other semantically similar error:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"To help with lower back pain, some effective exercises include:\\n\\n- **Cat-Cow Stretch**: Begin on hands and knees, then alternate between arching your back up (cat) and letting it sag down (cow). Aim for 10-15 repetitions.\\n- **Bird Dog**: From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold each extension for about 5 seconds and switch sides. Do 10 repetitions per side.\\n- **Pelvic Tilts**: Lie on your back with knees bent, tighten your abdominal muscles, and tilt your pelvis upward to flatten your lower back against the floor. Hold for 10 seconds and repeat 8-12 times.\\n\\nThese gentle exercises can help alleviate discomfort and prevent future episodes. However, it's always best to consult with a healthcare professional before starting new exercise routines.\""
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep significantly impacts overall health by supporting physical repair, mental well-being, and cognitive function. During sleep, the body repairs tissues, consolidates memories, and releases hormones that regulate growth and appetite. Adequate sleep, typically 7-9 hours for adults, in a proper environment helps maintain these processes, contributing to better physical health, mental clarity, and emotional stability. Conversely, poor sleep or sleep disorders like insomnia can negatively affect overall health and well-being.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress and headaches include drinking water to stay hydrated, applying cold or warm compresses to the head or neck, resting in a dark, quiet room, gently massaging the temples and neck, and using essential oils like peppermint or lavender. Additionally, practices such as deep breathing, progressive muscle relaxation, grounding techniques, taking short walks in nature, and listening to calming music can help alleviate stress.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Exercises that can help with lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n\\n- **Bird Dog:** From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Perform 10 repetitions per side.\\n\\n- **Partial Crunches:** Lie on your back with knees bent, cross arms over chest, tighten stomach muscles, and raise shoulders off the floor. Hold briefly, then lower. Do 8-12 repetitions.\\n\\n- **Knee-to-Chest Stretch:** Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n\\n- **Pelvic Tilts:** Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting pelvis up slightly. Hold for 10 seconds. Repeat 8-12 times.\\n\\nThese exercises, performed gently and regularly, can help alleviate and prevent lower back pain. As always, consult with a healthcare professional before starting new exercises, especially if you have any existing health conditions.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep has a significant impact on overall health. It is essential for physical well-being, mental health, and cognitive function. During sleep, the body repairs tissues, consolidates memories, and releases hormones that regulate growth and appetite. Adequate sleep (typically 7-9 hours for adults) supports the immune system, reduces stress, and promotes emotional stability. Poor sleep or sleep disturbances like insomnia can lead to physical health issues such as headaches, fatigue, and digestive problems, as well as mental health challenges like increased stress and mood disturbances. Therefore, maintaining good sleep hygiene and ensuring quality sleep are vital for overall health and wellness.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress and headaches include:\\n\\n- Deep breathing exercises (inhale for 4 counts, hold for 4, exhale for 4)\\n- Progressive muscle relaxation (tensing and releasing muscle groups)\\n- Grounding techniques (naming things you see, hear, feel, smell, and taste)\\n- Taking short walks, preferably in nature\\n- Listening to calming music\\n- Drinking water to stay hydrated\\n- Applying cold or warm compresses to the head or neck\\n- Resting in a dark, quiet room\\n- Gentle massage of temples and neck\\n- Using essential oils like peppermint or lavender\\n\\nThese methods can help provide immediate relief and promote overall relaxation.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### â“ Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall.\n",
        "\n",
        "##### Answer:\n",
        "\n",
        "It can be hard to articulate a query in a way that makes it crystal-clear for a search algorithm to interpret the way the user intended. Missing assumptions, ambiguities, and we are in the main (at least until recently) pre-conditioned to providing keywords for searching, not longer form prompts. So reformulating the query if a way of expanding the search space in the hope of returning potentially strong candidate results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. We split the full document into large \"parent\" chunks (e.g. 2000 characters).\n",
        "2. Each parent chunk is further split into smaller \"child\" chunks (e.g. 400 characters).\n",
        "3. The child chunks are stored in a VectorStore, while the parent chunks are stored in an in-memory docstore.\n",
        "4. When we query our Retriever, we do a similarity search comparing our query vector to the child chunks.\n",
        "5. Instead of returning the child chunks, we return their associated parent chunks.\n",
        "\n",
        "The basic idea is:\n",
        "\n",
        "- **Search** for small, focused chunks (better semantic matching)\n",
        "- **Return** big chunks (richer surrounding context)\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by defining our parent and child splitters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"wellness_parent_child\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"wellness_parent_child\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(raw_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To help with lower back pain, the recommended exercises include:\\n\\n- **Cat-Cow Stretch:** Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n- **Bird Dog:** From hands and knees, extend opposite arm and leg while keeping your core engaged. Hold for 5 seconds, then switch sides. Do 10 repetitions per side.\\n- **Partial Crunches:** Lie on your back with knees bent, cross arms over chest, tighten stomach muscles and raise shoulders off the floor. Hold briefly, then lower. Do 8-12 repetitions.\\n- **Knee-to-Chest Stretch:** Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n- **Pelvic Tilts:** Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting pelvis slightly. Hold for 10 seconds, repeat 8-12 times.\\n\\nThese gentle stretching and strengthening exercises can help alleviate lower back discomfort and prevent future issues.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep significantly affects overall health in several ways. It is crucial for physical health, mental well-being, and cognitive function. During sleep, the body repairs tissues, consolidates memories, and releases hormones that regulate growth and appetite. Adults generally need 7-9 hours of sleep per night. Good sleep quality supports healthy immune function, maintains mood stability, and enhances concentration and learning. Poor sleep or sleep disturbances can lead to increased risk of health issues such as fatigue, headaches, impaired cognitive function, and emotional stress. Therefore, maintaining healthy sleep habits and hygiene is vital for overall wellness.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress and headaches include practicing deep breathing, engaging in progressive muscle relaxation, doing grounding exercises, taking short walks especially in nature, listening to calming music, and practicing mindfulness or meditation. For headaches specifically, natural remedies include drinking plenty of water to stay hydrated, applying cold or warm compresses to the head or neck, resting in a dark, quiet room, gently massaging the temples and neck, using essential oils like peppermint or lavender, and maintaining a regular sleep schedule.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Exercises that can help with lower back pain include:\\n\\n- **Cat-Cow Stretch**: Start on your hands and knees, then alternate between arching your back up (like a cat) and letting it sag down (like a cow). Perform 10-15 repetitions.\\n\\n- **Bird Dog**: From hands and knees, extend opposite arm and leg simultaneously while keeping your core engaged. Hold each extension for about 5 seconds, then switch sides. Do 10 repetitions per side.\\n\\n- **Pelvic Tilts**: Lie on your back with knees bent. Flatten your lower back against the floor by tightening your abdominal muscles and tilting your pelvis up slightly. Hold for 10 seconds and repeat 8-12 times.\\n\\n- **Partial Crunches**: Lie on your back with knees bent, cross your arms over your chest, tighten your stomach muscles, and lift your shoulders off the floor briefly. Then lower back down. Do 8-12 repetitions.\\n\\n- **Knee-to-Chest Stretch**: Lie on your back and pull one knee toward your chest, keeping the other foot flat on the floor. Hold for 15-30 seconds, then switch legs.\\n\\nThese exercises are gentle and designed to stretch and strengthen muscles that support your lower back, helping alleviate discomfort and prevent future issues. As always, consult with a healthcare professional before starting new exercises, especially if you have existing health conditions.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep has a significant impact on overall health. It is essential for physical repair, mental well-being, and cognitive functions such as memory and learning. During sleep, tissues are repaired, hormones that regulate growth and appetite are released, and the brain consolidates memories. Adequate sleep (7-9 hours per night) supports immune function, reduces stress, and boosts mental health. Poor sleep or sleep disturbances like insomnia can negatively affect physical health, mental well-being, and increase vulnerability to illness. Maintaining good sleep hygieneâ€”such as keeping a consistent schedule, creating a comfortable sleep environment, and practicing relaxation techniquesâ€”can help promote better sleep quality and, consequently, improve overall health.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress include deep breathing exercises, progressive muscle relaxation, grounding techniques (such as naming things you see, hear, feel, smell, and taste), taking short walks especially in nature, and listening to calming music. \\n\\nFor headaches, natural remedies include staying well-hydrated by drinking water, applying cold or warm compresses to the head or neck, resting in a dark and quiet room, gentle massage of the temples and neck, using essential oils such as peppermint or lavender, maintaining a regular sleep schedule, and using caffeine in small amounts if appropriate.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(raw_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = QdrantVectorStore.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"wellness_guide_semantic_chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Exercises that can help alleviate lower back pain include:\\n\\n- **Cat-Cow Stretch:** Start on hands and knees, alternate between arching your back up (cat) and letting it sag down (cow). Do 10-15 repetitions.\\n\\n- **Partial Crunches:** Lie on your back with knees bent, cross arms over chest, tighten stomach muscles and raise shoulders off the floor. Hold briefly, then lower. Do 8-12 repetitions.\\n\\n- **Knee-to-Chest Stretch:** Lie on your back, pull one knee toward your chest while keeping the other foot flat. Hold for 15-30 seconds, then switch legs.\\n\\n- **Pelvic Tilts:** Lie on your back with knees bent, flatten your back against the floor by tightening abs and tilting pelvis up slightly. Hold for 10 seconds, repeat 8-12 times.\\n\\nThese gentle stretching and strengthening exercises can help relieve lower back discomfort and may prevent future episodes.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What exercises can help with lower back pain?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sleep significantly impacts overall health by supporting physical restoration, mental well-being, and cognitive functions. During sleep, the body repairs tissues, regenerates cells, and releases hormones that regulate growth and appetite. Adequate sleepâ€”typically 7-9 hours for adultsâ€”also helps consolidate memories and improve learning. Good sleep quality is crucial for maintaining a healthy immune system, managing stress, and preventing chronic conditions such as hypertension, diabetes, and mental health issues. Conversely, poor sleep can lead to fatigue, impair cognitive function, weaken immunity, and increase the risk of various health problems. Therefore, prioritizing consistent, quality sleep is essential for overall health and wellness.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"How does sleep affect overall health?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Some natural remedies for stress and headaches include:\\n\\n- Deep breathing exercises: Inhale for 4 counts, hold for 4, exhale for 4, and hold for 4.\\n- Progressive muscle relaxation: Tense and relax muscle groups, such as from toes to head.\\n- Grounding techniques: Name 5 things you see, 4 you hear, 3 you feel, 2 you smell, and 1 you taste.\\n- Taking short walks, preferably in nature.\\n- Listening to calming music.\\n- Applying peppermint or lavender essential oils.\\n- Staying well-hydrated by drinking water.\\n- Resting in a dark, quiet room.\\n- Gentle massage of temples and neck.\\n\\nThese approaches can help reduce tension, promote relaxation, and alleviate headache symptoms naturally.'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What are some natural remedies for stress and headaches?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### â“ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?\n",
        "\n",
        "##### Answer:\n",
        "\n",
        "Highly repetative questions with similar sentence structure are likely to be problematic for semantic search because they will have high semantic overlap and it will be harder to discriminate what differentiates each question (which \n",
        "is what is needed) rather than what makes them similar. \n",
        "\n",
        "BM25 may work better here since its likely to give more weight to terms that are likely to be differentiators rather than common sentence structure words found in FAQS (where/what/how do.....).\n",
        "\n",
        "Generally a hybrid approach (lexical + semantic search) gives the flexibility of addressing these kinds of questions, plus any other kinds of questions that don't fit this pattern and may be a better fit for semantic search. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "---\n",
        "\n",
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "### ðŸ—ï¸ Activity #1:\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against each other.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparison between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image](retreivers.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/var/folders/bz/qcwzc_9j6zgggtsc_fbjryy40000gp/T/ipykernel_57514/1536617908.py:5: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
            "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
            "/var/folders/bz/qcwzc_9j6zgggtsc_fbjryy40000gp/T/ipykernel_57514/1536617908.py:7: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
            "  generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n"
          ]
        }
      ],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
        "\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "845c9a73ea2c4ffe97b5fce6ad471c58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/45 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9453c465bb84294af0d1c46cbaf1d2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/45 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node 008b1a11-ea96-4a03-92e7-3208ed98f988 does not have a summary. Skipping filtering.\n",
            "Node 92213be8-9f63-4a2a-ba19-5b61231d823c does not have a summary. Skipping filtering.\n",
            "Node e829393e-c301-4d89-882c-fa70db2478e5 does not have a summary. Skipping filtering.\n",
            "Node b59f4f31-092f-4e2e-b67a-8bf728bb6b12 does not have a summary. Skipping filtering.\n",
            "Node 8a3e52c6-6068-490c-8376-19e338ba99c6 does not have a summary. Skipping filtering.\n",
            "Node 597af84d-8268-4245-affa-57f5c0f340d0 does not have a summary. Skipping filtering.\n",
            "Node 48febde2-a429-4585-bd9e-33835f1b3b7e does not have a summary. Skipping filtering.\n",
            "Node c9ca0f72-b214-47b9-83b5-2684db6b513a does not have a summary. Skipping filtering.\n",
            "Node bb6c46c7-c506-4df5-aee7-4b89cfa7705c does not have a summary. Skipping filtering.\n",
            "Node b18808b3-495c-4389-8e40-0b045af62cd8 does not have a summary. Skipping filtering.\n",
            "Node d5a3b4e6-eabe-4563-8649-2c870269c7e1 does not have a summary. Skipping filtering.\n",
            "Node fc69f427-972d-4540-8ded-428283acfb4b does not have a summary. Skipping filtering.\n",
            "Node ca1644e6-b7fa-4b13-b063-3409cead38da does not have a summary. Skipping filtering.\n",
            "Node bf7259d4-2847-44d8-acd3-c0e1371e0624 does not have a summary. Skipping filtering.\n",
            "Node 28c500be-e9e1-4a03-bc11-cf767b497c12 does not have a summary. Skipping filtering.\n",
            "Node ebb0dc43-8725-44c1-9e66-00a082bfa76a does not have a summary. Skipping filtering.\n",
            "Node d84c9cde-7f2d-4bf2-8d21-a0d6f327a572 does not have a summary. Skipping filtering.\n",
            "Node 74d47c60-eca1-47c3-aff7-75e48c985a7e does not have a summary. Skipping filtering.\n",
            "Node a16b6714-f01c-4508-8622-bcbc00b6af65 does not have a summary. Skipping filtering.\n",
            "Node bb18ba07-6a25-48f5-9aad-6a4e516c4777 does not have a summary. Skipping filtering.\n",
            "Node 367ad4c3-4fd6-4591-83c7-0df839525045 does not have a summary. Skipping filtering.\n",
            "Node a432fc7a-e810-49cd-91b6-b947e16041d2 does not have a summary. Skipping filtering.\n",
            "Node 21e621a9-8bbd-4170-9c8f-bafb42017c8b does not have a summary. Skipping filtering.\n",
            "Node b884e5f7-cf06-4652-8f3a-ab42729b14ad does not have a summary. Skipping filtering.\n",
            "Node 5b3ea655-2af1-4946-9db3-b91e965c5365 does not have a summary. Skipping filtering.\n",
            "Node 4ff08ada-f891-4ddd-ac35-d421832b243a does not have a summary. Skipping filtering.\n",
            "Node cd6ac87c-d167-4e57-8b87-352d0e7851b9 does not have a summary. Skipping filtering.\n",
            "Node 0716ada4-c313-4b0b-b095-437561fdfb1e does not have a summary. Skipping filtering.\n",
            "Node 740cfeba-0037-4a5b-9f24-f03f3fe6e28e does not have a summary. Skipping filtering.\n",
            "Node 7a1b914b-6aaa-4685-8a24-560af8a1a3d4 does not have a summary. Skipping filtering.\n",
            "Node 15cef409-28a4-4b6a-b0f1-a2551fcf870b does not have a summary. Skipping filtering.\n",
            "Node e8929e3f-6c13-4d5e-b546-44bbae41e0db does not have a summary. Skipping filtering.\n",
            "Node e65a7771-129a-4c14-b342-7c5b87b57508 does not have a summary. Skipping filtering.\n",
            "Node f5bcb373-8089-4771-9f1a-967e9068f769 does not have a summary. Skipping filtering.\n",
            "Node b32aa18e-d679-4203-9079-d342f417e3e0 does not have a summary. Skipping filtering.\n",
            "Node 91a8cf5b-14fa-4fa3-9ce3-93802dfd733a does not have a summary. Skipping filtering.\n",
            "Node ac5e6cf8-209c-441f-b126-9a700a2eceb5 does not have a summary. Skipping filtering.\n",
            "Node 3d90af44-68ac-401c-868a-f66d9d54e43f does not have a summary. Skipping filtering.\n",
            "Node d624a409-6642-4ef6-9dc9-30b1767c0fd2 does not have a summary. Skipping filtering.\n",
            "Node 947502b4-ecbc-4103-bdbd-811b54acb061 does not have a summary. Skipping filtering.\n",
            "Node 58662d1c-8c52-4b29-b0a6-fd03a928f7fc does not have a summary. Skipping filtering.\n",
            "Node 56f8fadc-82b5-4321-a7f2-d6904adbd2d6 does not have a summary. Skipping filtering.\n",
            "Node 89ba2ccf-cc69-4501-b345-98f07c4d7bd6 does not have a summary. Skipping filtering.\n",
            "Node 5c8cccca-3e31-40e4-91a3-9f66ba202fad does not have a summary. Skipping filtering.\n",
            "Node 5d374c39-3b45-4dc5-8063-7ce63f40ae8e does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05199204bae145c08872af6948530b70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying EmbeddingExtractor:   0%|          | 0/45 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a8feba1cf754e568cbcbd9b7a714a4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying ThemesExtractor:   0%|          | 0/45 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fb0a88d61d643a8b685faae46753353",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying NERExtractor:   0%|          | 0/45 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11a6462cdec842aca50673f3f4c2530c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CosineSimilarityBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0067e5cbc2eb4907a0593c5d49152a72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04c1b26dd52a4a40986fa5c712ed214a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08028dfb4965434e8ec22e888cc3dd65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4c08c485b03452fb918943af6aeb0c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "from ragas.testset.synthesizers import (\n",
        "    SingleHopSpecificQuerySynthesizer,\n",
        ")\n",
        "query_distribution = [\n",
        "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0),\n",
        "]\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "# new since 0.4.2\n",
        "dataset = generator.generate_with_chunks(wellness_docs, testset_size=20, query_distribution=query_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "query_style\n",
              "MISSPELLED         5\n",
              "PERFECT_GRAMMAR    5\n",
              "POOR_GRAMMAR       5\n",
              "WEB_SEARCH_LIKE    5\n",
              "Name: user_input, dtype: int64"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas().groupby('query_style')['user_input'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "query_length\n",
              "LONG      8\n",
              "MEDIUM    9\n",
              "SHORT     3\n",
              "Name: user_input, dtype: int64"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas().groupby('query_length')['user_input'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.to_csv(path='eval_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up  metrics and  langsmith experiments \n",
        "from langsmith import Client\n",
        "import uuid\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Assignment11 Synthetic Data - AIE9 - {uuid.uuid4()}\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Synthetic Data for Advanced Retrievers\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data_row in dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bz/qcwzc_9j6zgggtsc_fbjryy40000gp/T/ipykernel_57514/3723646950.py:1: DeprecationWarning: Importing ContextPrecision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import ContextPrecision\n",
            "  from ragas.metrics import ContextPrecision, LLMContextRecall, ContextEntityRecall\n",
            "/var/folders/bz/qcwzc_9j6zgggtsc_fbjryy40000gp/T/ipykernel_57514/3723646950.py:1: DeprecationWarning: Importing LLMContextRecall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import LLMContextRecall\n",
            "  from ragas.metrics import ContextPrecision, LLMContextRecall, ContextEntityRecall\n",
            "/var/folders/bz/qcwzc_9j6zgggtsc_fbjryy40000gp/T/ipykernel_57514/3723646950.py:1: DeprecationWarning: Importing ContextEntityRecall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import ContextEntityRecall\n",
            "  from ragas.metrics import ContextPrecision, LLMContextRecall, ContextEntityRecall\n",
            "/var/folders/bz/qcwzc_9j6zgggtsc_fbjryy40000gp/T/ipykernel_57514/3723646950.py:5: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
            "  evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n"
          ]
        }
      ],
      "source": [
        "from ragas.metrics import ContextPrecision, LLMContextRecall, ContextEntityRecall\n",
        "from ragas import evaluate, RunConfig, EvaluationDataset\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_retreiver(candidate_retreiver, retriever_name):\n",
        "  for test_row in dataset:\n",
        "    response = candidate_retreiver.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "    test_row.eval_sample.response = response[\"response\"].content\n",
        "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "\n",
        "  evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "  result = evaluate(\n",
        "      dataset=evaluation_dataset,\n",
        "      metrics=[ContextPrecision(), LLMContextRecall(), ContextEntityRecall()],\n",
        "      llm=evaluator_llm,\n",
        "      run_config=custom_run_config,\n",
        "      experiment_name=retriever_name   # name for this run in LangSmith\n",
        "\n",
        "  )\n",
        "  return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df4b6d81d3c045f49ff81379a7553515",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.8699, 'context_recall': 0.9875, 'context_entity_recall': 0.3227}"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retriever_result = evaluate_retreiver(naive_retrieval_chain, 'naive_retriever')\n",
        "naive_retriever_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89d618b648f140a1bd20c56c7628e59b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.4153, 'context_recall': 0.5125, 'context_entity_recall': 0.1313}"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retriever_result = evaluate_retreiver(bm25_retrieval_chain, 'bm25_retriever')\n",
        "bm25_retriever_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08b2ba1739414b9b83c012ffaa46db75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.9667, 'context_recall': 0.9750, 'context_entity_recall': 0.3718}"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_result = evaluate_retreiver(contextual_compression_retrieval_chain, 'contextual_compression_retriever')\n",
        "contextual_compression_retrieval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9facc73e926b4716bf1f9cd8df395c52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.7869, 'context_recall': 1.0000, 'context_entity_recall': 0.3231}"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_result = evaluate_retreiver(multi_query_retrieval_chain, 'multi_query_retriever')\n",
        "multi_query_retrieval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "464546de86a64e19bdab80925a4d3804",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.8750, 'context_recall': 0.9500, 'context_entity_recall': 0.2748}"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_result = evaluate_retreiver(parent_document_retrieval_chain, 'parent_document_retriever')\n",
        "\n",
        "parent_document_retrieval_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12e028727c844ea68c9530ac31e78b2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.5497, 'context_recall': 0.9875, 'context_entity_recall': 0.2713}"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_result = evaluate_retreiver(ensemble_retrieval_chain, 'ensemble_retriever')\n",
        "ensemble_retrieval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "results_df = DataFrame([eval(naive_retriever_result.__repr__()), \n",
        "eval(bm25_retriever_result.__repr__()),\n",
        "eval(contextual_compression_retrieval_result.__repr__()),\n",
        "eval(multi_query_retrieval_result.__repr__()),\n",
        "eval(parent_document_retrieval_result.__repr__()),\n",
        "eval(ensemble_retrieval_result.__repr__()) ], \n",
        "index=['naive_retriever', \n",
        "'bm25_retriever', \n",
        "'contextual_compression_retrieval', \n",
        "'multi_query_retrieval', \n",
        "'parent_document_retrieval',\n",
        "'ensemble_retrieval'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_entity_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>naive_retriever</th>\n",
              "      <td>0.8699</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.3227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bm25_retriever</th>\n",
              "      <td>0.4153</td>\n",
              "      <td>0.5125</td>\n",
              "      <td>0.1313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression_retrieval</th>\n",
              "      <td>0.9667</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.3718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query_retrieval</th>\n",
              "      <td>0.7869</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.3231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document_retrieval</th>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.2748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_retrieval</th>\n",
              "      <td>0.5497</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.2713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  context_precision  context_recall  \\\n",
              "naive_retriever                              0.8699          0.9875   \n",
              "bm25_retriever                               0.4153          0.5125   \n",
              "contextual_compression_retrieval             0.9667          0.9750   \n",
              "multi_query_retrieval                        0.7869          1.0000   \n",
              "parent_document_retrieval                    0.8750          0.9500   \n",
              "ensemble_retrieval                           0.5497          0.9875   \n",
              "\n",
              "                                  context_entity_recall  \n",
              "naive_retriever                                  0.3227  \n",
              "bm25_retriever                                   0.1313  \n",
              "contextual_compression_retrieval                 0.3718  \n",
              "multi_query_retrieval                            0.3231  \n",
              "parent_document_retrieval                        0.2748  \n",
              "ensemble_retrieval                               0.2713  "
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.to_csv('scores.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the data that we get from Langsmith to run our dataset of evals on (20 examples) (appreciate this includes the evals and output costs as well, but its more about the relative rather than absolute spend)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image](lsmith_pd.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Retriever</th>\n",
              "      <th>time</th>\n",
              "      <th>tokens</th>\n",
              "      <th>Cost $</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>naive_retriever</td>\n",
              "      <td>124.19s</td>\n",
              "      <td>309,910</td>\n",
              "      <td>0.1566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bm25</td>\n",
              "      <td>67.22</td>\n",
              "      <td>150900</td>\n",
              "      <td>0.0738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contextual compression</td>\n",
              "      <td>57.02s</td>\n",
              "      <td>125600</td>\n",
              "      <td>0.0580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>multiquery</td>\n",
              "      <td>222.55s</td>\n",
              "      <td>390300</td>\n",
              "      <td>0.1904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>parent document</td>\n",
              "      <td>56.98s</td>\n",
              "      <td>160100</td>\n",
              "      <td>0.0833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>emsemble</td>\n",
              "      <td>223.02s</td>\n",
              "      <td>552800</td>\n",
              "      <td>0.2684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Retriever     time   tokens  Cost $\n",
              "0         naive_retriever  124.19s  309,910  0.1566\n",
              "1                    bm25    67.22   150900  0.0738\n",
              "2  contextual compression   57.02s   125600  0.0580\n",
              "3              multiquery  222.55s   390300  0.1904\n",
              "4         parent document   56.98s   160100  0.0833\n",
              "5                emsemble  223.02s   552800  0.2684"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('langsmith_retreival_compute.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "Have created a synthetic dataset of 20 Q & As based on the HealthWellnessGuide, and compared the result of 5 different variations of retreiver against a baseline of \"naive\" RAG. \n",
        "\n",
        "\n",
        "To **evaluate the retriever**, the key metrics are context precision and recall which basically is concerned with whether the retreived chunks contain the information needed to answer the question and **how much** of the retreived chunks are relevant to the question\n",
        "\n",
        "On this particular dataset:\n",
        "**BM25** doesn't work well  being comparitively poor on both metrics. We'd expect it to do well on questions whose characteristics (See above) are 'web_search_like' and 'short' in length but less on the other styles (which are the majority)\n",
        "\n",
        "**Multi-query retreival** brings back the most comprehensive set of chunks required to answer the question (I suppose by reformulating the question asked picks up more nuance) at the expense of some noise - retreives some irrelevant chunks. \n",
        "\n",
        "**Contextual compression** seems to have the best trade-off of precision and recall both of which are close to the best. The reranking step adds a little cost (0.2 cents per call). **Parent-document** performs almost as well on p/r metrics and latency cost\n",
        "\n",
        "**Ensemble** throws everything at the problem but comes off less favorably particularly on precision with too much irrelevant chunks retreived (possibly due to BM25) and of course its computationally and $ expensive \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
